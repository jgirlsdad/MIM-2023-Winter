{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More `pandas` Tools\n",
    "\n",
    "<img src=\"images/pandas1.jpeg\" style=\"width:500px;height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"images/pandas3.jpeg\" style=\"width:500px;height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use mapping tools to transform data frame columns\n",
    "- Handle missing data\n",
    "- Use GroupBy objects to organize and aggregate data\n",
    "- <b>Coding techniques</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "<p>\n",
    "We are going to develope a workflow to answer some questions using our Animal dataset from last week\n",
    "\n",
    "1. Read Data\n",
    "2. Investigate data (let's consider this the 1st time we see the data)\n",
    "3. Clean data <b>if needed</b>\n",
    "4. Create new Data if needed\n",
    "5. Compute needed statistics\n",
    "6. Rinse and Repeat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T13:46:35.871220Z",
     "start_time": "2022-05-25T13:46:34.685068Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll work with the Austin Animal Center dataset and with data from [King County's Department of Assessments (Seattle housing data)](https://info.kingcounty.gov/assessor/DataDownload/default.aspx). On King County's page download two files: \"Real Property Sales\" and \"Residential Building\". Then unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:46:24.796654Z",
     "start_time": "2022-05-26T15:46:23.668230Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "json_url = 'https://data.austintexas.gov/resource/9t4d-g238.json'\n",
    "animals = pd.read_json(json_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Primary Question</b>:<br>\n",
    "What is the average age for adopted animals?\n",
    "\n",
    "<p>\n",
    "<b>Secondary Quesiton(s):</b>\n",
    "    \n",
    "- In our shelter, are cats or dogs older?\n",
    "- Are there more males or females in the shelter?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T16:38:44.527348Z",
     "start_time": "2022-05-26T16:38:44.506341Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T16:48:40.916165Z",
     "start_time": "2022-05-26T16:48:40.862875Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#animals.info()\n",
    "animals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T18:13:59.892510Z",
     "start_time": "2022-05-25T18:13:59.868582Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals[\"age_upon_outcome\"].unique()\n",
    "#animals[\"age_upon_outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are 4 different time units used in \"age_upon_outcome\"\n",
    "- days\n",
    "- months\n",
    "- years\n",
    "- weeks\n",
    "\n",
    "<p>\n",
    "How to handle NULL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `apply()`\n",
    "\n",
    "- Used to apply a function to a Dataframe or Series\n",
    "- Used when more complex operations need to be performed\n",
    "- `.map()` and `.applymap()` are other options\n",
    "- `.apply()` more versatile than `.map()`\n",
    "- apply(function_name,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T18:39:57.603966Z",
     "start_time": "2022-05-26T18:39:57.564690Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def setAge(row):\n",
    "    age_old = row[\"age_upon_outcome\"]\n",
    "    \n",
    "    if (age_old != \"NULL\"):\n",
    "        spl = age_old.split(\" \")\n",
    "\n",
    "        if (spl[1] == \"months\"):\n",
    "            age_new = int(spl[0])\n",
    "        elif (spl[1] == \"years\"):\n",
    "            age_new = int(spl[0])*12\n",
    "        elif (spl[1] == \"days\"):\n",
    "            age_new = int(spl[0])/30\n",
    "        else:\n",
    "            print(\"roh-roh error \",spl[0],spl[1])\n",
    "            age_new = -2 \n",
    "    else:\n",
    "        age_new = -1\n",
    "        \n",
    "        \n",
    "    return age_new\n",
    "\n",
    "\n",
    "animals[\"age_months\"] = animals.apply(setAge,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T18:42:30.678264Z",
     "start_time": "2022-05-26T18:42:30.643911Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def setAge(row):\n",
    "## Convert \"age_upon_outcome\" to months \n",
    "##    Years =   x12\n",
    "##    Months =  x1 \n",
    "##    Weeks =  /4\n",
    "##    days =  /30\n",
    "##  Set NULL values to NaN \n",
    "##  Set bad values to -2 \n",
    "    age_old = row[\"age_upon_outcome\"]\n",
    "    \n",
    "    if (age_old != \"NULL\"):  # process  values that are NOT NULL\n",
    "##  Split the field into 2 columns... split on white spaces        \n",
    "        spl = age_old.split(\" \")\n",
    "        if (spl[1] == \"months\" or spl[1] == \"month\"):\n",
    "            age_new = int(spl[0])\n",
    "        elif (spl[1] == \"years\" or spl[1] == \"year\"):\n",
    "            age_new = int(spl[0])*12\n",
    "        elif (spl[1] == \"weeks\" or spl[1] == \"week\"):\n",
    "            age_new = int(spl[0])/4\n",
    "        elif (spl[1] == \"days\" or spl[1] == \"day\"):\n",
    "            age_new = int(spl[0])/30\n",
    "        else:  # This covers cases we have not anticipated OR are bad values \n",
    "            print(\"roh-roh error \",spl[0],spl[1])\n",
    "            age_new = -2 \n",
    "    else:\n",
    "        age_new = np.nan\n",
    "        \n",
    "    return age_new\n",
    "\n",
    "animals[\"age_months\"] = animals.apply(setAge,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T18:42:53.182915Z",
     "start_time": "2022-05-26T18:42:53.156403Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals[\"age_months\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mapping\n",
    "\n",
    "### `Series.map()`\n",
    "\n",
    "The `.map()` method applies a transformation to every entry in the Series. This transformation  \"maps\" each value from the Series to a new value. A transformation can be defined by a function, Series, or dictionary - usually we'll use functions.\n",
    "\n",
    "The `.apply()` method is similar to the `.map()` method for Series, but can only use functions. It has more powerful uses when working with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T18:59:30.347021Z",
     "start_time": "2022-05-26T18:59:30.337706Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def one_year(age):\n",
    "    if age == '1 year':\n",
    "        age =  '1 years'\n",
    "    elif age == \"1 month\":\n",
    "        age = \"1 months\"\n",
    "    elif age == \"1 week\":\n",
    "        age = \"1 weeks\"   \n",
    "    return age\n",
    "    \n",
    "animals['new_age1'] = animals['age_upon_outcome'].map(one_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T19:02:33.437972Z",
     "start_time": "2022-05-26T19:02:33.425091Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals['new_age1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More Sophisticated Mapping\n",
    "\n",
    "Let's use `.map()` to turn sex_upon_outcome into a category with three values (called **ternary**): male, female, or unknown. \n",
    "\n",
    "First, explore the unique values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One of our secondary questions is \"Do males live longer than females?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animals['sex_upon_outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T14:31:25.643109Z",
     "start_time": "2022-05-27T14:31:25.633826Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sex_mapper(status):\n",
    "    if status in ['Neutered Male', 'Intact Male']:\n",
    "        return 'Male'\n",
    "    elif status in ['Spayed Female', 'Intact Female']:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T14:31:26.406280Z",
     "start_time": "2022-05-27T14:31:26.375913Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals['new_sex1'] = animals['sex_upon_outcome'].map(sex_mapper)\n",
    "animals.loc[:, ['sex_upon_outcome', 'new_sex1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lambda Functions\n",
    "\n",
    "Simple functions can be defined just when you need them, when you would call the function. \n",
    "- These are called **lambda functions**. These functions are **anonymous** and disappear immediately after use.\n",
    "- The functions help preserve resources\n",
    "\n",
    "Let's use a lambda function to get rid of 'Other' in the \"animal_type' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals[animals['animal_type'] == 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['animal_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals['animal_type'].map(lambda x: np.nan if x == 'Other' else x).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't modified the actual data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animals['animal_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "A lot of the times we'll have missing information in our data set. This can sometimes be troublesome in what we're trying to do.\n",
    "\n",
    "So far, we've been doing some preprocessing/cleaning to answer questions. Now we're going to handle the missing values in our data.\n",
    "\n",
    "There are a few strategies we can choose from and they each have their special use case.\n",
    "\n",
    "> Before making changes, it's convenient to make changes to a copy instead of overwriting data. We'll keep all our changes in `animals_clean` which will be a [copy](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html) of the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean = animals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fill with a Relevant Value\n",
    "\n",
    "A lot of times we already have an idea of how we want to specify that a value was missing and replace it with a value that makes more sense than an \"empty\" value.\n",
    "\n",
    "For example, it might make sense to fill the value as \"MISSING\" or \"UNKNOWN\". This way it's clearer when do more analysis.\n",
    "\n",
    "> We can use Pandas' [`fillna()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) to replace missing values with something specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals.info()\n",
    "#animals[animals['name'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#animals_name_filled = animals.fillna({'name':'UNKNOWN'}) \n",
    "animals_only_names = animals[['name']].fillna(value='UNKNOWN')\n",
    "print(animals_only_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To keep changes in DataFrame, overwrite the column\n",
    "animals_clean[['name']] = animals_only_names\n",
    "animals_clean[animals_clean['name'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fill with a Reasonable Value\n",
    "\n",
    "Other times we don't know what the missing value was but we might have a reasonable guess. This allows us to still use the data point (row) in our analysis.\n",
    "\n",
    "> Beware that filling in missing values can lead to you drawing incorrect conclusions. If most of the data from a column are missing, it's going to appear that the value you filled it in with is more common that it actually was!\n",
    "\n",
    "A lot of the time we'll use the _mean_ or _median_ for numerical values. Sometimes values like $0$ make sense since it might make sense in the context of how the data was collected.\n",
    "\n",
    "With categorical values, you might choose to fill the missing values with the most common value (the *mode*).\n",
    "\n",
    "> Similar to the previous subsection, we can use the `fillna()` method after specifying the value to fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's find the most common value for `outcome_subtype`\n",
    "outcome_subtype_counts = animals['outcome_subtype'].value_counts()\n",
    "outcome_subtype_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This gets us just the values in order of most frequent to least frequent\n",
    "outcome_subtype_ordered = outcome_subtype_counts.index\n",
    "print(outcome_subtype_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the first one\n",
    "most_common_outcome_subtype = outcome_subtype_ordered[0]\n",
    "\n",
    "most_common_outcome_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Using the built-in mode() method\n",
    "# Note this is Series so we have to get the first element (which is the value)\n",
    "most_common_outcome_subtype = animals['outcome_subtype'].mode()[0]\n",
    "most_common_outcome_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Similar to the previous subsection, we can use fillna() and update the DF\n",
    "animals_clean['outcome_subtype'] = animals['outcome_subtype']\\\n",
    ".fillna(most_common_outcome_subtype)\n",
    "animals_clean.tail()\n",
    "print(animals_clean['outcome_subtype'].value_counts())\n",
    "print(animals['outcome_subtype'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Drop Missing Data\n",
    "\n",
    "You should try to keep as much relevant data as possible, but sometimes the other methods don't make as much sense and it's better to remove or **drop** the missing data.\n",
    "\n",
    "We typically drop missing data if very little data would be lost and/or trying to fill in the values wouldn't make sense for our use case. For example, if you're trying to predict the outcome based on the other features/columns it might not make sense to fill in those missing values with something you can't confirm.\n",
    "\n",
    "> We noticed that `outcome_type` had only a few missing values. It might not be worth trying to handle those few missing values. We can pretend that the `outcome_type` was an important feature and without it the rest of the row's data is of little importance to us.\n",
    ">\n",
    "> So we'll decide to drop the row if a value from `outcome_type` is missing. We'll use Pandas' [`dropna()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This will drop any row (axis=0) or column (axis=1) that has missing values\n",
    "animals_clean = animals_clean.dropna(   # Note we're overwriting animals_clean\n",
    "                                axis=0, # This is the default & will drop rows;\n",
    "                                        # axis=1 for cols\n",
    "                                subset=['outcome_type'] # Specific labels\n",
    "                                                        # to consider (defaults to \"all\")\n",
    ")\n",
    "animals_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Before and After\n",
    "\n",
    "We can now see all the work we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Original data\n",
    "animals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Missing data cleaned\n",
    "animals_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis Time \n",
    "- Cleaning is now Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aggregating over DataFrames: `.groupby()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Those of you familiar with SQL have probably used the GROUP BY command. (And if you haven't, you'll see it very soon!) Pandas has this, too.\n",
    "\n",
    "The `.groupby()` method is especially useful for aggregate functions applied to the data grouped in particular ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean.groupby('animal_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can group by multiple columns, and also return a DataFrameGroupBy object\n",
    "\n",
    "Notice the object type [DataFrameGroupBy](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `.groups` and `.get_group()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T14:13:36.380957Z",
     "start_time": "2022-05-27T14:13:36.320199Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This retuns each group indexed by the group name:\n",
    "# e.g. 'Bird', along with the row indices of each value\n",
    "animals_clean.groupby('animal_type').groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once we know we are working with a type of object, it opens up a suite of attributes and methods. One attribute we can look at is groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T14:14:31.570384Z",
     "start_time": "2022-05-27T14:14:31.514655Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Once we know the group indices, we can return the groups using those indices.\n",
    "animals_clean.groupby('animal_type').get_group('Dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multi-Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Same goes for multi index groupbys\n",
    "animal_outcome = animals_clean.groupby(['animal_type', 'outcome_type'])\n",
    "animal_outcome.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# animal_outcome.groups is a dictionary, so we can access the group names using keys()\n",
    "animal_outcome.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can then get a specific group, such as Cats that were adopted\n",
    "animal_outcome.get_group(('Cat', 'Adoption'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once again, as we will see in SQL, groupby objects are intended to be used with aggregation. In SQL, we will see that our queries that include GROUP BY require aggregation performed on columns.\n",
    "\n",
    "We can use `.sum()`, `.mean()`, `.count()`, `.max()`, `.min()`, etc. Find a list of common aggregations [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean.groupby('animal_type').mean()\n",
    "ages_mean = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean.groupby('animal_type').mean()\n",
    "ages_mean = animals_clean.groupby('animal_type').mean()\n",
    "#ages_mean = animals_clean.groupby('animal_type',as_index=False).mean()\n",
    "#print(ages_mean[ages_mean[\"animal_type\"] == \"Cat\"][\"age_months\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "animals_clean.groupby('animal_type').max()\n",
    "#animals_clean.groupby('animal_type').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " You can perform multiple groupby operations at the same times use the agg() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animals.groupby(by=['outcome_type']).agg({\"age_months\":[\"mean\",\"max\",\"min\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Level Up: Pivoting a DataFrame\n",
    "\n",
    "### `.pivot_table()`\n",
    "\n",
    "Those of you familiar with Excel have probably used Pivot Tables. Pandas has a similar functionality.\n",
    "\n",
    "Grouping by two different columns can be very helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But it has the unsavory side effect of creating a two-level index. This can be a good time to use `.pivot_table()`.\n",
    "\n",
    "(There is also a `.pivot()`. For the somewhat subtle differences, see [here](https://stackoverflow.com/questions/30960338/pandas-difference-between-pivot-and-pivot-table-why-is-only-pivot-table-workin).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"sex\": [\"male\", \"male\", \"male\", \"male\", \"male\",\n",
    "                          \"female\", \"female\", \"female\", \"female\"],\n",
    "                    \"num_puppies\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                          \"one\", \"one\", \"two\", \"two\"],\n",
    "                    \"breed\": [\"terrier\", \"retriever\", \"retriever\", \"terrier\",\n",
    "                          \"terrier\", \"retriever\", \"terrier\", \"terrier\",\n",
    "                          \"retriever\"],\n",
    "                    \"past_owners\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                    \"family_members\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This first example aggregates values by taking the sum.\n",
    "\n",
    "table = pd.pivot_table(df, values='past_owners', index=['sex', 'num_puppies'],\n",
    "                     columns=['breed'], aggfunc=np.sum)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Use `.pivot_table()` to add up the number of my tasks by category. Hint: Use `sum()` as your aggregating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tasks = pd.DataFrame({'category': ['house', 'house', 'school', 'school'],\n",
    "                      'descr': ['kitchen', 'laundry', 'git', 'Python'],\n",
    "                      'priority': [2, 3, 4, 1], 'num_tasks': [2, 1, 2, 3]})\n",
    "\n",
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    <code>tasks.pivot_table(values='num_tasks', index='category', aggfunc=sum)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Level Up: Methods for Combining DataFrames: `.join()`, `.merge()`, `pd.concat()`\n",
    "\n",
    "### `.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "toy1 = pd.DataFrame([[63, 142], [33, 47]], columns=['age', 'HP'])\n",
    "toy2 = pd.DataFrame([[63, 100], [33, 200]], columns=['age', 'MP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "toy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "toy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can't just join these as they are, since we haven't specified our suffixes.\n",
    "\n",
    "toy1.join(toy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "toy1.join(toy2, lsuffix='1', rsuffix='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we don't want to keep both, we could set the overlapping column as the index in each DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "toy1.set_index('age').join(toy2.set_index('age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more on this method, check out the [doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### `.merge()`\n",
    "\n",
    "Or we could use `.merge()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "toy1.merge(toy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ds_chars = pd.read_csv('data/ds_chars.csv', index_col=0)\n",
    "ds_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "states = pd.read_csv('data/states.csv', index_col=0)\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `how` Parameter\n",
    "\n",
    "This parameter in both `.join()` and `.merge()` tells the compiler what sort of join to effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ds_chars.merge(states,\n",
    "               left_on='home_state',\n",
    "               right_on='state',\n",
    "               how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ds_chars.merge(states,\n",
    "               left_on='home_state',\n",
    "               right_on='state',\n",
    "               how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `pd.concat()`\n",
    "\n",
    "This method takes a *list* of pandas objects as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_full = pd.concat([ds_chars, states])\n",
    "ds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`pd.concat()`–– and many other pandas operations –– make use of an `axis` parameter. For this particular method I need to specify whether I want to concatenate the DataFrames *row-wise* (`axis=0`) or *column-wise* (`axis=1`). The default is `axis=0`, so let's override that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_full = pd.concat([ds_chars, states], axis=1)\n",
    "ds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## King County Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data scientists, we want to build a model to predict the sale price of a house in Seattle in 2019, based on its square footage. We know that the King County Department of Assessments has comprehensive data available on real property sales in the Seattle area. We need to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You'll need to use a new encoding here. List of all encodings here:\n",
    "# https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "\n",
    "# Both of these csv files have many columns, so we'll just pre-select\n",
    "# which ones we want to use.\n",
    "\n",
    "sales_df = pd.read_csv('/Users/gdamico/Downloads/EXTR_RPSale.csv',\n",
    "                       encoding='latin-1',\n",
    "                       usecols=['Major', 'Minor', 'DocumentDate', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df = pd.read_csv('~/Downloads/EXTR_ResBldg.csv',\n",
    "                     usecols=['Major', 'Minor', 'SqFtTotLiving', 'ZipCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Level Up sections for more on merging!\n",
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that we're missing ZIP codes for many of the sales transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data[sales_data['ZipCode'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exercises\n",
    "Important: Do these *in order*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. What percentage of housing records are missing ZIP codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    <code>sales_data['ZipCode'].isna().sum() / sales_data.shape[0]</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's drop the rows with missing zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales_data = sales_data.loc[~sales_data['ZipCode'].isna(), :]\n",
    "\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2. Investigate and drop rows with invalid values in the SalePrice and SqFtTotLiving columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>One possible answer here</summary>\n",
    "    <code>sales_data = sales_data[sales_data['SalePrice'] > 10000]</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3. Investigate and handle non-numeric ZipCode values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Can you find a way to shorten ZIP+4 codes to the first five digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_integer(x):\n",
    "    try:\n",
    "        _ = int(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "sales_data.loc[sales_data['ZipCode'].apply(is_integer) == False, 'ZipCode'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>One possible answer here</summary>\n",
    "    <code>def five_digit_ZIP(x):\n",
    "    try:\n",
    "        return int(str(x)[:5])\n",
    "    except:\n",
    "        return x\n",
    "sales_data['ZipCode'] = sales_data['ZipCode'].map(five_digit_ZIP)\n",
    "sales_data = sales_data.loc[sales_data['ZipCode'].apply(is_integer) == True, :]\n",
    "sales_data['ZipCode'] = sales_data['ZipCode'].map(int)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4. Add a column for PricePerSqFt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['PricePerSqFt'] = sales_data['SalePrice'] / sales_data['SqFtTotLiving']</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5. Subset the data to 2021 sales only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can assume that the DocumentDate is approximately the sale date. The first thing you should do is convert the date to a datetime object with the following code:\n",
    "\n",
    "<code>sales_data['DocumentDate'] = pd.to_datetime(sales_data['DocumentDate'])</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['DocumentDate'] = pd.to_datetime(sales_data['DocumentDate'])\n",
    "sales_data = sales_data.loc[sales_data['DocumentDate'] > '12/31/2020']</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "6. What is the mean price per square foot for a house sold in Seattle in 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data['PricePerSqFt'].mean()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "7. I'm interested in seeing all the Major ID nos. that cover multiple ZIP codes. The first step will be to:\n",
    "\n",
    "- group by 'Major' and then check out the ZIP codes for each 'Major' value. Let's store that in a new variable called \"grouped\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>grouped = sales_data.groupby('Major')['ZipCode'].value_counts()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8. Then I'll need to:\n",
    "\n",
    "- iterate over that Series, looking for entries where the first half of the index (the 'Major' ID) corresponds to two different \"second halves\" of the index (the 'ZipCode'). One way to proceed would be to initialize an empty list, and then add elements of the index to it when the 'Major' value of an entry matches the 'Major' value of the next entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "<code>multiples = []\n",
    "for j in range(len(grouped) - 1):\n",
    "    if grouped.index[j+1][0] == grouped.index[j][0]:\n",
    "        multiples.append(grouped.index[j])\n",
    "        multiples.append(grouped.index[j+1])</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "9. Which ZIP Code has had the most sales in 2021, and how many has it had?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>sales_data.groupby('ZipCode').count().sort_values(by='Major', ascending=False).head(1)</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "10. Looking ahead: Plotting!\n",
    "\n",
    "a. What happens if we run:\n",
    "\n",
    "<code>sales_data['SqFtTotLiving'].hist();</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "b. What about:\n",
    "\n",
    "<code>sales_data_sorted = sales_data.sort_values('SqFtTotLiving')\n",
    "sales_data_sorted.plot(x='SqFtTotLiving', y='SalePrice');</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "c. How could we plot the number of sales by date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer here</summary>\n",
    "    <code>ctr = sales_data.groupby('DocumentDate').count().reset_index()\n",
    "ctr.plot(x='DocumentDate', y='SalePrice') # _Any_ column will work here for the  y-value!;</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
